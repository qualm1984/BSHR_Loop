{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tractorjuice/BSHR_Loop/blob/main/demo02/Building_David_Shapiro_AI_Body_of_Knowledge_Part_1_Collect_YouTube_Videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07c1e3b9",
      "metadata": {
        "id": "07c1e3b9"
      },
      "source": [
        "# David Shapiro AI Body of Knowledge Using Langchain & OpenAI\n",
        "## Part 1, collect the required data for processing\n",
        "\n",
        "This example shows how to create and query an internal knowledge base using ChatGPT.\n",
        "\n",
        "This does not require a GPU runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0UqlAAxTXnGF",
      "metadata": {
        "id": "0UqlAAxTXnGF"
      },
      "source": [
        "## Set Up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K3l-ZazUZPR2",
      "metadata": {
        "id": "K3l-ZazUZPR2"
      },
      "source": [
        "###Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "trki7a-jZNzf",
      "metadata": {
        "id": "trki7a-jZNzf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BPsvKKXIo3f2",
      "metadata": {
        "id": "BPsvKKXIo3f2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "KB_FOLDER = \"/content/gdrive/Shareddrives/AI/DavidShapiroKB\"  # Google drive folder to save the knowledgebase\n",
        "YT = os.path.join(KB_FOLDER, \"youtube\")  # Sub-directory for YouTube FAIS datastore files\n",
        "YT_DATASTORE = os.path.join(YT, \"datastore\")  # Sub-directory for YouTube FAIS datastore files\n",
        "YT_AUDIO = os.path.join(YT, \"audio\")  # Sub-directory for audio files\n",
        "YT_TRANSCRIPTS = os.path.join(YT_AUDIO, \"transcripts\")  # Sub-directory for transcripts of audio files\n",
        "YT_TRANSCRIPTS_TEXT = os.path.join(YT_TRANSCRIPTS, \"full_text\")  # Sub-directory for text of audio files\n",
        "YT_TRANSCRIPTS_WHISPER = os.path.join(YT_TRANSCRIPTS, \"whisper_chunks\")  # Sub-directory for Whisper chunks of audio files\n",
        "YT_TRANSCRIPTS_DATASTORE = os.path.join(YT_TRANSCRIPTS, \"datastore\")  # Sub-directory for books FAIS datastore file\n",
        "PODCAST = os.path.join(KB_FOLDER, \"podcast\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_DATASTORE = os.path.join(PODCAST, \"datastore\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_AUDIO = os.path.join(PODCAST, \"audio\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_TRANSCRIPTS = os.path.join(PODCAST, \"transcripts\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_TRANSCRIPTS_TEXT = os.path.join(PODCAST_TRANSCRIPTS, \"full_text\")  # Sub-directory for text of audio files\n",
        "PODCAST_TRANSCRIPTS_WHISPER = os.path.join(PODCAST_TRANSCRIPTS, \"whisper_chunks\")  # Sub-directory for Whisper chunks of audio files\n",
        "\n",
        "# Check if directory exists and if not, create its\n",
        "if not os.path.exists(KB_FOLDER):\n",
        "    os.makedirs(KB_FOLDER)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(YT_DATASTORE):\n",
        "    os.makedirs(YT_DATASTORE)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_AUDIO):\n",
        "    os.makedirs(YT_AUDIO)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS):\n",
        "    os.makedirs(YT_TRANSCRIPTS)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_TEXT):\n",
        "    os.makedirs(YT_TRANSCRIPTS_TEXT)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_WHISPER):\n",
        "    os.makedirs(YT_TRANSCRIPTS_WHISPER)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST):\n",
        "    os.makedirs(PODCAST)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_DATASTORE):\n",
        "    os.makedirs(PODCAST_DATASTORE)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_AUDIO):\n",
        "    os.makedirs(PODCAST_AUDIO)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_TRANSCRIPTS):\n",
        "    os.makedirs(PODCAST_TRANSCRIPTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Umxa-nBZIW5Q",
      "metadata": {
        "id": "Umxa-nBZIW5Q"
      },
      "source": [
        "## Find all David Shapiro YouTube Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nx154vPks4wz",
      "metadata": {
        "id": "nx154vPks4wz"
      },
      "outputs": [],
      "source": [
        "!pip install -q scrapetube\n",
        "import scrapetube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RRN_TlA_tI-O",
      "metadata": {
        "id": "RRN_TlA_tI-O"
      },
      "outputs": [],
      "source": [
        "#All David Shapiro Videos\n",
        "all_videos = scrapetube.get_search(\"https://www.youtube.com/@DaveShap/videos\")\n",
        "\n",
        "all_video_ids = [video['videoId'] for video in all_videos]\n",
        "print (all_video_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VCUW7szJ8n_8",
      "metadata": {
        "id": "VCUW7szJ8n_8"
      },
      "outputs": [],
      "source": [
        "# Deduplicate the lists\n",
        "\n",
        "unique_video_ids = []\n",
        "unique_video_ids = list(set(all_video_ids))\n",
        "print(unique_video_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BHTJz8bRakwn",
      "metadata": {
        "id": "BHTJz8bRakwn"
      },
      "source": [
        "## Store the list of videos in a local file for processing later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "orbk6Pjh-bt1",
      "metadata": {
        "id": "orbk6Pjh-bt1"
      },
      "outputs": [],
      "source": [
        "# Open the file in write mode to erase existing content\n",
        "with open(f'{YT_AUDIO}/videos.txt', 'w') as f:\n",
        "    pass\n",
        "\n",
        "total_videos = len(unique_video_ids)  # Get the total number of videos\n",
        "\n",
        "for idx, video_id in enumerate(unique_video_ids, start=1):\n",
        "    url = \"https://www.youtube.com/watch?v=\" + video_id\n",
        "    print(f\"Processing video {idx} of {total_videos}: {url}\")\n",
        "    with open(f'{YT_AUDIO}/videos.txt', 'a') as f:\n",
        "        f.write(f'{video_id}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g1vBRv2Ri5J8",
      "metadata": {
        "id": "g1vBRv2Ri5J8"
      },
      "source": [
        "### Download the audio from all the videos and store them on Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JD3yq0tGYa46",
      "metadata": {
        "id": "JD3yq0tGYa46"
      },
      "outputs": [],
      "source": [
        "!pip install -q yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gg0A13AbXctt",
      "metadata": {
        "id": "gg0A13AbXctt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yt_dlp as yt\n",
        "\n",
        "counter = 0\n",
        "total_videos = len(unique_video_ids)\n",
        "\n",
        "# Define download options\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'outtmpl': f'{YT_AUDIO}/clips/%(id)s.%(ext)s',\n",
        "}\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(os.path.join(YT_AUDIO, 'clips'), exist_ok=True)\n",
        "\n",
        "for video_id in unique_video_ids:\n",
        "    counter = counter + 1\n",
        "    url = \"https://www.youtube.com/watch?v=\" + video_id\n",
        "    path = os.path.join(YT_AUDIO, 'clips', f'{video_id}.webm')\n",
        "\n",
        "    if not os.path.isfile(path):\n",
        "        print(counter, \"of\", total_videos, \": Fetching new audio file \" + video_id)\n",
        "\n",
        "        try:\n",
        "            with yt.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([url])\n",
        "            with open(os.path.join(YT_AUDIO, 'processed_videos.txt'), 'a') as f:\n",
        "                f.write(url + \"\\n\")\n",
        "        except:\n",
        "            print(f'Video {url} is unavailable, skipping.')\n",
        "\n",
        "    else:\n",
        "        print(counter, \"of\", total_videos, \": Existing file: \" + path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0UqlAAxTXnGF"
      ],
      "gpuClass": "premium",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "b1677b440931f40d89ef8be7bf03acb108ce003de0ac9b18e8d43753ea2e7103"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
